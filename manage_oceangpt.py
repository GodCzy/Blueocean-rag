#!/usr/bin/env python3
"""
OceanGPTæ¨¡å‹ç®¡ç†è„šæœ¬
ç”¨äºä¸‹è½½ã€åˆ‡æ¢å’Œç®¡ç†ä¸åŒç‰ˆæœ¬çš„OceanGPTæ¨¡å‹

 æ›´å¤šä½¿ç”¨è¯´æ˜è§ DEPLOYMENT_GUIDE.mdã€‚
"""

import argparse
import json
import sys
import os
from pathlib import Path
import subprocess

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open("config.json", "r", encoding="utf-8") as f:
        return json.load(f)

def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    with open("config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)

def list_available_models():
    """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
    config = load_config()
    models = config.get("oceangpt_models", {})
    
    print("ğŸŒŠ å¯ç”¨çš„OceanGPTæ¨¡å‹:")
    print("-" * 80)
    
    for key, model_info in models.items():
        status = "âœ… æ¨è" if model_info.get("recommended") else "ğŸ“‹ å¯é€‰"
        features = []
        
        if model_info.get("supports_multimodal"):
            features.append("ğŸ–¼ï¸ å¤šæ¨¡æ€")
        if model_info.get("supports_code"):
            features.append("ğŸ’» ä»£ç ç”Ÿæˆ")
        if not features:
            features.append("ğŸ“ æ–‡æœ¬")
        
        model_path = Path("models") / model_info["name"]
        installed = "âœ… å·²å®‰è£…" if model_path.exists() else "âŒ æœªå®‰è£…"
        
        print(f"ğŸ“¦ {model_info['name']}")
        print(f"   ğŸ“‹ æè¿°: {model_info['description']}")
        print(f"   ğŸ—ï¸  åŸºç¡€æ¨¡å‹: {model_info['base_model']}")
        print(f"   ğŸ”§ åŠŸèƒ½: {' | '.join(features)}")
        print(f"   ğŸ“ çŠ¶æ€: {status} | {installed}")
        print(f"   ğŸ”— ModelScope: {model_info['modelscope_id']}")
        print(f"   ğŸ”— HuggingFace: {model_info['huggingface_id']}")
        print()

def list_datasets():
    """åˆ—å‡ºå¯ç”¨çš„æ•°æ®é›†"""
    config = load_config()
    datasets = config.get("ocean_instruct_datasets", {})
    
    print("ğŸ“š å¯ç”¨çš„OceanInstructæ•°æ®é›†:")
    print("-" * 60)
    
    for key, dataset_info in datasets.items():
        dataset_path = Path("datasets/ocean_instruct") / dataset_info["name"]
        installed = "âœ… å·²ä¸‹è½½" if dataset_path.exists() else "âŒ æœªä¸‹è½½"
        
        print(f"ğŸ“Š {dataset_info['name']}")
        print(f"   ğŸ“‹ æè¿°: {dataset_info['description']}")
        print(f"   ğŸ“ å¤§å°: {dataset_info['size']}")
        print(f"   ğŸ·ï¸  ç±»å‹: {dataset_info['type']}")
        print(f"   ğŸ“ çŠ¶æ€: {installed}")
        print(f"   ğŸ”— ModelScope: {dataset_info['modelscope_id']}")
        print(f"   ğŸ”— HuggingFace: {dataset_info['huggingface_id']}")
        print()

def download_from_modelscope(model_id: str, local_path: Path) -> bool:
    """ä»ModelScopeä¸‹è½½æ¨¡å‹"""
    try:
        print(f"ğŸ“¥ ä»ModelScopeä¸‹è½½: {model_id}")
        
        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†modelscope
        try:
            import modelscope
        except ImportError:
            print("âŒ ModelScopeæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...")
            subprocess.run([sys.executable, "-m", "pip", "install", "modelscope"], check=True)
            import modelscope
        
        from modelscope import snapshot_download
        
        snapshot_download(
            model_id=model_id,
            cache_dir=str(local_path.parent),
            local_dir=str(local_path)
        )
        
        print(f"âœ… ä¸‹è½½å®Œæˆ: {local_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ModelScopeä¸‹è½½å¤±è´¥: {e}")
        return False

def download_from_huggingface(model_id: str, local_path: Path) -> bool:
    """ä»HuggingFaceä¸‹è½½æ¨¡å‹"""
    try:
        print(f"ğŸ“¥ ä»HuggingFaceä¸‹è½½: {model_id}")
        
        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†huggingface_hub
        try:
            import huggingface_hub
        except ImportError:
            print("âŒ HuggingFace Hubæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...")
            subprocess.run([sys.executable, "-m", "pip", "install", "huggingface_hub"], check=True)
            import huggingface_hub
        
        from huggingface_hub import snapshot_download
        
        snapshot_download(
            repo_id=model_id,
            local_dir=str(local_path),
            local_dir_use_symlinks=False
        )
        
        print(f"âœ… ä¸‹è½½å®Œæˆ: {local_path}")
        return True
        
    except Exception as e:
        print(f"âŒ HuggingFaceä¸‹è½½å¤±è´¥: {e}")
        return False

def download_model(model_name: str, source: str = "modelscope") -> bool:
    """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
    config = load_config()
    models = config.get("oceangpt_models", {})
    
    # æŸ¥æ‰¾æŒ‡å®šæ¨¡å‹
    target_model = None
    for key, model_info in models.items():
        if model_info["name"] == model_name or key == model_name:
            target_model = model_info
            break
    
    if not target_model:
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
        print("ğŸ’¡ ä½¿ç”¨ 'python manage_oceangpt.py list' æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        return False
    
    model_path = Path("models") / target_model["name"]
    
    if model_path.exists():
        print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {target_model['name']}")
        return True
    
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹: {target_model['name']}")
    print(f"ğŸ“‹ æè¿°: {target_model['description']}")
    print(f"ğŸ“ ä¸‹è½½æº: {source}")
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•
    model_path.parent.mkdir(parents=True, exist_ok=True)
    
    # å°è¯•ä¸‹è½½
    success = False
    if source == "modelscope":
        success = download_from_modelscope(target_model["modelscope_id"], model_path)
    else:
        success = download_from_huggingface(target_model["huggingface_id"], model_path)
    
    # å¦‚æœå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æº
    if not success:
        fallback_source = "huggingface" if source == "modelscope" else "modelscope"
        print(f"âš ï¸  ä¸»è¦æºä¸‹è½½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æº: {fallback_source}")
        
        if fallback_source == "modelscope":
            success = download_from_modelscope(target_model["modelscope_id"], model_path)
        else:
            success = download_from_huggingface(target_model["huggingface_id"], model_path)
    
    return success

def download_dataset(dataset_name: str, source: str = "modelscope") -> bool:
    """ä¸‹è½½æŒ‡å®šæ•°æ®é›†"""
    config = load_config()
    datasets = config.get("ocean_instruct_datasets", {})
    
    # æŸ¥æ‰¾æŒ‡å®šæ•°æ®é›†
    target_dataset = None
    for key, dataset_info in datasets.items():
        if dataset_info["name"] == dataset_name or key == dataset_name:
            target_dataset = dataset_info
            break
    
    if not target_dataset:
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®é›†: {dataset_name}")
        print("ğŸ’¡ ä½¿ç”¨ 'python manage_oceangpt.py list-datasets' æŸ¥çœ‹å¯ç”¨æ•°æ®é›†")
        return False
    
    dataset_path = Path("datasets/ocean_instruct") / target_dataset["name"]
    
    if dataset_path.exists():
        print(f"âœ… æ•°æ®é›†å·²å­˜åœ¨: {target_dataset['name']}")
        return True
    
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ•°æ®é›†: {target_dataset['name']}")
    print(f"ğŸ“‹ æè¿°: {target_dataset['description']}")
    print(f"ğŸ“ ä¸‹è½½æº: {source}")
    
    # åˆ›å»ºæ•°æ®é›†ç›®å½•
    dataset_path.parent.mkdir(parents=True, exist_ok=True)
    
    # å°è¯•ä¸‹è½½
    success = False
    if source == "modelscope":
        success = download_from_modelscope(target_dataset["modelscope_id"], dataset_path)
    else:
        success = download_from_huggingface(target_dataset["huggingface_id"], dataset_path)
    
    # å¦‚æœå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æº
    if not success:
        fallback_source = "huggingface" if source == "modelscope" else "modelscope"
        print(f"âš ï¸  ä¸»è¦æºä¸‹è½½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æº: {fallback_source}")
        
        if fallback_source == "modelscope":
            success = download_from_modelscope(target_dataset["modelscope_id"], dataset_path)
        else:
            success = download_from_huggingface(target_dataset["huggingface_id"], dataset_path)
    
    return success

def switch_model(model_name: str) -> bool:
    """åˆ‡æ¢é»˜è®¤æ¨¡å‹"""
    config = load_config()
    models = config.get("oceangpt_models", {})
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    target_model = None
    for key, model_info in models.items():
        if model_info["name"] == model_name or key == model_name:
            target_model = model_info
            break
    
    if not target_model:
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
        return False
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
    model_path = Path("models") / target_model["name"]
    if not model_path.exists():
        print(f"âŒ æ¨¡å‹æœªä¸‹è½½: {target_model['name']}")
        print(f"ğŸ’¡ ä½¿ç”¨ 'python manage_oceangpt.py download {model_name}' ä¸‹è½½æ¨¡å‹")
        return False
    
    # æ›´æ–°é…ç½®
    config["model_name"] = target_model["name"]
    
    # æ›´æ–°æ¨¡å‹è·¯å¾„
    if "model_local_paths" in config:
        config["model_local_paths"][target_model["name"]] = f"./models/{target_model['name']}"
    
    save_config(config)
    
    print(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {target_model['name']}")
    print(f"ğŸ“‹ æè¿°: {target_model['description']}")
    
    features = []
    if target_model.get("supports_multimodal"):
        features.append("ğŸ–¼ï¸ å¤šæ¨¡æ€æ”¯æŒ")
    if target_model.get("supports_code"):
        features.append("ğŸ’» ä»£ç ç”Ÿæˆ")
    
    if features:
        print(f"ğŸ”§ åŠŸèƒ½: {' | '.join(features)}")
    
    return True

def status():
    """æ˜¾ç¤ºå½“å‰çŠ¶æ€"""
    config = load_config()
    current_model = config.get("model_name", "æœªè®¾ç½®")
    
    print("ğŸŒŠ è“æµ·æ™ºè¯¢ - OceanGPTçŠ¶æ€")
    print("=" * 50)
    print(f"ğŸ“¦ å½“å‰æ¨¡å‹: {current_model}")
    
    if current_model != "æœªè®¾ç½®":
        models = config.get("oceangpt_models", {})
        current_model_info = None
        
        for key, model_info in models.items():
            if model_info["name"] == current_model:
                current_model_info = model_info
                break
        
        if current_model_info:
            print(f"ğŸ“‹ æè¿°: {current_model_info['description']}")
            print(f"ğŸ—ï¸  åŸºç¡€æ¨¡å‹: {current_model_info['base_model']}")
            
            features = []
            if current_model_info.get("supports_multimodal"):
                features.append("ğŸ–¼ï¸ å¤šæ¨¡æ€")
            if current_model_info.get("supports_code"):
                features.append("ğŸ’» ä»£ç ç”Ÿæˆ")
            if features:
                print(f"ğŸ”§ åŠŸèƒ½: {' | '.join(features)}")
            
            model_path = Path("models") / current_model_info["name"]
            status = "âœ… å·²å®‰è£…" if model_path.exists() else "âŒ æœªå®‰è£…"
            print(f"ğŸ“ çŠ¶æ€: {status}")
    
    print()
    print("ğŸ“Š å·²å®‰è£…çš„æ¨¡å‹:")
    models_dir = Path("models")
    if models_dir.exists():
        installed_models = [d.name for d in models_dir.iterdir() if d.is_dir()]
        if installed_models:
            for model in installed_models:
                print(f"  âœ… {model}")
        else:
            print("  âŒ æš‚æ— å·²å®‰è£…çš„æ¨¡å‹")
    else:
        print("  âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")

def main():
    parser = argparse.ArgumentParser(
        description="ğŸŒŠ è“æµ·æ™ºè¯¢ - OceanGPTæ¨¡å‹ç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python manage_oceangpt.py list                          # åˆ—å‡ºå¯ç”¨æ¨¡å‹
  python manage_oceangpt.py download OceanGPT-o-7B-v0.1  # ä¸‹è½½æ¨¡å‹
  python manage_oceangpt.py switch OceanGPT-o-7B-v0.1    # åˆ‡æ¢æ¨¡å‹
  python manage_oceangpt.py status                        # æŸ¥çœ‹çŠ¶æ€
  python manage_oceangpt.py list-datasets                 # åˆ—å‡ºæ•°æ®é›†
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # åˆ—å‡ºæ¨¡å‹
    subparsers.add_parser("list", help="åˆ—å‡ºå¯ç”¨æ¨¡å‹")
    
    # åˆ—å‡ºæ•°æ®é›†
    subparsers.add_parser("list-datasets", help="åˆ—å‡ºå¯ç”¨æ•°æ®é›†")
    
    # ä¸‹è½½æ¨¡å‹
    download_parser = subparsers.add_parser("download", help="ä¸‹è½½æ¨¡å‹")
    download_parser.add_argument("model_name", help="æ¨¡å‹åç§°")
    download_parser.add_argument("--source", choices=["modelscope", "huggingface"], 
                               default="modelscope", help="ä¸‹è½½æº (é»˜è®¤: modelscope)")
    
    # ä¸‹è½½æ•°æ®é›†
    dataset_parser = subparsers.add_parser("download-dataset", help="ä¸‹è½½æ•°æ®é›†")
    dataset_parser.add_argument("dataset_name", help="æ•°æ®é›†åç§°")
    dataset_parser.add_argument("--source", choices=["modelscope", "huggingface"], 
                               default="modelscope", help="ä¸‹è½½æº (é»˜è®¤: modelscope)")
    
    # åˆ‡æ¢æ¨¡å‹
    switch_parser = subparsers.add_parser("switch", help="åˆ‡æ¢é»˜è®¤æ¨¡å‹")
    switch_parser.add_argument("model_name", help="æ¨¡å‹åç§°")
    
    # çŠ¶æ€
    subparsers.add_parser("status", help="æ˜¾ç¤ºå½“å‰çŠ¶æ€")
    
    args = parser.parse_args()
    
    if args.command == "list":
        list_available_models()
    elif args.command == "list-datasets":
        list_datasets()
    elif args.command == "download":
        success = download_model(args.model_name, args.source)
        sys.exit(0 if success else 1)
    elif args.command == "download-dataset":
        success = download_dataset(args.dataset_name, args.source)
        sys.exit(0 if success else 1)
    elif args.command == "switch":
        success = switch_model(args.model_name)
        sys.exit(0 if success else 1)
    elif args.command == "status":
        status()
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 