#!/usr/bin/env python3
"""
OceanGPT é›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯• OceanGPT æ¨¡å‹åœ¨è“æµ·æ™ºè¯¢ç³»ç»Ÿä¸­çš„ä½¿ç”¨
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.core.oceangpt_manager import OceanGPTManager, ModelConfig
from src.utils.logger import get_logger

logger = get_logger(__name__)

async def test_oceangpt():
    """æµ‹è¯• OceanGPT æ¨¡å‹"""
    print("ğŸŒŠ OceanGPT é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    # é…ç½® OceanGPT æ¨¡å‹ - ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°
    print("âš™ï¸ é…ç½® OceanGPT æ¨¡å‹...")
    model_config = ModelConfig(
        model_name="OceanGPT-o-7B",  # ç®€åŒ–çš„æ¨¡å‹åç§°ï¼Œä¼šè‡ªåŠ¨åŒ¹é…
        model_path="./models/OceanGPT-o-7B",
        load_in_4bit=True,
        device="auto",
        supports_multimodal=True,
        model_source="huggingface"  # æˆ– "modelscope"
    )
    
    # åˆ›å»º OceanGPT ç®¡ç†å™¨
    print("ğŸ¤– åˆå§‹åŒ– OceanGPT ç®¡ç†å™¨...")
    oceangpt_manager = OceanGPTManager(model_config)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    model_path = Path(model_config.model_path)
    if not model_path.exists():
        print(f"ğŸ“¥ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("ğŸ”„ æ­£åœ¨å°è¯•ä¸‹è½½æ¨¡å‹...")
        
        try:
            download_success = await oceangpt_manager.download_model_from_official()
            if not download_success:
                print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
                print("ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹:")
                print("   HuggingFace:")
                print(f"   git clone https://huggingface.co/zjunlp/OceanGPT-o-7B {model_path}")
                print("   æˆ–è€…")
                print(f"   huggingface-cli download --resume-download zjunlp/OceanGPT-o-7B --local-dir {model_path}")
                print()
                print("   ModelScope:")
                print(f"   git clone https://www.modelscope.cn/zjunlp/OceanGPT-o-7B.git {model_path}")
                return False
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ æ­£åœ¨åŠ è½½ OceanGPT æ¨¡å‹...")
    try:
        model_loaded = await oceangpt_manager.load_model()
        if not model_loaded:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            return False
        
        print("âœ… OceanGPT æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å‡ºé”™: {e}")
        print("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§")
        print("   2. ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜ (å»ºè®® 8GB+)")
        print("   3. å¦‚æœä½¿ç”¨ CPUï¼Œè¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜")
        print("   4. æ£€æŸ¥æ˜¯å¦å·²å®‰è£…æ‰€éœ€ä¾èµ–: qwen-vl-utils")
        return False
    
    # æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
    print("\nğŸ§ª æµ‹è¯•æ–‡æœ¬ç”ŸæˆåŠŸèƒ½...")
    test_prompts = [
        "æµ·æ´‹ä¸­é±¼ç±»ç™½ç‚¹ç—…çš„ç—‡çŠ¶å’Œæ²»ç–—æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æµ·æ°´é±¼å…»æ®–ä¸­å¦‚ä½•é¢„é˜²ç»†èŒæ€§ç–¾ç—…ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯æµ·æ´‹é±¼ç±»çƒ‚é³ƒç—…ï¼Ÿå¦‚ä½•è¯Šæ–­å’Œæ²»ç–—ï¼Ÿ"
    ]
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\nğŸ” æµ‹è¯• {i}: {prompt}")
        try:
            response = await oceangpt_manager.generate_response(prompt)
            print(f"ğŸ¤– OceanGPTå›ç­”: {response[:200]}..." if len(response) > 200 else f"ğŸ¤– OceanGPTå›ç­”: {response}")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå›ç­”å¤±è´¥: {e}")
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    model_info = oceangpt_manager.get_model_info()
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   æ¨¡å‹åç§°: {model_info.get('model_name', 'Unknown')}")
    print(f"   è®¾å¤‡: {model_info.get('device', 'Unknown')}")
    print(f"   æ”¯æŒå¤šæ¨¡æ€: {model_info.get('supports_multimodal', False)}")
    
    print("\nâœ… OceanGPT é›†æˆæµ‹è¯•å®Œæˆï¼")
    return True

async def test_rag_with_oceangpt():
    """æµ‹è¯• RAG ä¸ OceanGPT çš„é›†æˆ"""
    print("\nğŸ”— æµ‹è¯• RAG + OceanGPT é›†æˆ")
    print("=" * 50)
    
    from src.api.rag_api import RAGService
    
    # åˆ›å»º OceanGPT é…ç½®
    oceangpt_config = ModelConfig(
        model_name="zjunlp/OceanGPT-o-7B",
        model_path="./models/OceanGPT-o-7B",
        load_in_4bit=True,
        device="auto"
    )
    
    # åˆ›å»º RAG æœåŠ¡
    print("ğŸ”§ åˆå§‹åŒ– RAG æœåŠ¡...")
    rag_service = RAGService(
        data_dir="src/data",
        index_path="./temp_index",
        oceangpt_config=oceangpt_config
    )
    
    # åˆå§‹åŒ– OceanGPT
    print("ğŸ¤– åˆå§‹åŒ– OceanGPT...")
    oceangpt_ready = await rag_service.initialize_oceangpt()
    
    if oceangpt_ready:
        print("âœ… OceanGPT åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•é—®ç­”
        test_query = "æµ·æ´‹é±¼ç±»çƒ‚é³ƒç—…çš„ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ"
        print(f"\nğŸ§ª æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        result = await rag_service.ask(test_query)
        print(f"ğŸ¤– å›ç­”: {result['answer']}")
        print(f"ğŸ“š ä½¿ç”¨äº† {len(result['source_documents'])} ä¸ªæ–‡æ¡£")
        print(f"â±ï¸ è€—æ—¶: {result['elapsed_time']:.2f}ç§’")
        print(f"ğŸ”— OceanGPTçŠ¶æ€: {'å¯ç”¨' if result['has_oceangpt'] else 'ä¸å¯ç”¨'}")
    else:
        print("âš ï¸ OceanGPT åˆå§‹åŒ–å¤±è´¥ï¼Œä½† RAG æœåŠ¡ä»å¯ä½¿ç”¨æ£€ç´¢åŠŸèƒ½")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ OceanGPT é›†æˆæµ‹è¯•")
    print("\nğŸ’¡ æç¤ºï¼šæœ¬æµ‹è¯•å°†ä½¿ç”¨æ­£ç¡®çš„ OceanGPT æ¨¡å‹")
    print("   - æ¨¡å‹: zjunlp/OceanGPT-o-7B")
    print("   - åŸºäº: Qwen2.5-VL-7B-Instruct") 
    print("   - ä¸“ä¸š: æµ·æ´‹ç§‘å­¦å’Œæ°´ç”ŸåŠ¨ç‰©ç–¾ç—…è¯Šæ–­")
    print("   - å¤šæ¨¡æ€: æ”¯æŒå›¾åƒå’Œæ–‡æœ¬è¾“å…¥")
    
    try:
        # æµ‹è¯•åŸºæœ¬çš„ OceanGPT åŠŸèƒ½
        success = asyncio.run(test_oceangpt())
        
        if success:
            # æµ‹è¯• RAG é›†æˆ
            asyncio.run(test_rag_with_oceangpt())
        else:
            print("âš ï¸ åŸºç¡€æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡ RAG é›†æˆæµ‹è¯•")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 