#!/usr/bin/env python3
"""
OceanGPTæ¨¡å‹ä¸‹è½½è„šæœ¬
æ”¯æŒModelScopeå’ŒHuggingFaceï¼Œå…·æœ‰æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
"""

import os
import json
import sys
import time
import logging
from pathlib import Path
from typing import Optional, Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/download.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def load_config() -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open('config.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def download_from_modelscope(model_id: str, local_dir: str) -> bool:
    """ä»ModelScopeä¸‹è½½æ¨¡å‹"""
    try:
        from modelscope import snapshot_download
        logger.info(f"å¼€å§‹ä»ModelScopeä¸‹è½½æ¨¡å‹: {model_id}")
        logger.info(f"ä¸‹è½½åˆ°ç›®å½•: {local_dir}")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(local_dir, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹
        snapshot_download(
            model_id=model_id,
            cache_dir=local_dir,
            revision='master'
        )
        
        logger.info(f"âœ… ModelScopeä¸‹è½½å®Œæˆ: {model_id}")
        return True
        
    except ImportError:
        logger.error("âŒ ModelScope SDKæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install modelscope")
        return False
    except Exception as e:
        logger.error(f"âŒ ModelScopeä¸‹è½½å¤±è´¥: {e}")
        return False

def download_from_huggingface(model_id: str, local_dir: str) -> bool:
    """ä»HuggingFaceä¸‹è½½æ¨¡å‹"""
    try:
        from huggingface_hub import snapshot_download
        logger.info(f"å¼€å§‹ä»HuggingFaceä¸‹è½½æ¨¡å‹: {model_id}")
        logger.info(f"ä¸‹è½½åˆ°ç›®å½•: {local_dir}")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(local_dir, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹
        snapshot_download(
            repo_id=model_id,
            local_dir=local_dir,
            local_dir_use_symlinks=False,
            allow_patterns=["*.json", "*.txt", "*.safetensors", "*.bin", "*.model", "*.jpg", "*.png"]
        )
        
        logger.info(f"âœ… HuggingFaceä¸‹è½½å®Œæˆ: {model_id}")
        return True
        
    except ImportError:
        logger.error("âŒ HuggingFace Hubæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install huggingface_hub")
        return False
    except Exception as e:
        logger.error(f"âŒ HuggingFaceä¸‹è½½å¤±è´¥: {e}")
        return False

def check_model_integrity(model_path: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    model_path = Path(model_path)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        'config.json',
        'tokenizer.json',
        'tokenizer_config.json'
    ]
    
    missing_files = []
    for file in required_files:
        if not (model_path / file).exists():
            missing_files.append(file)
    
    # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶
    safetensors_files = list(model_path.glob('*.safetensors'))
    if not safetensors_files:
        missing_files.append('*.safetensors (æ¨¡å‹æƒé‡æ–‡ä»¶)')
    
    if missing_files:
        logger.warning(f"âš ï¸ ç¼ºå°‘æ–‡ä»¶: {', '.join(missing_files)}")
        return False
    
    logger.info("âœ… æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
    return True

def download_oceangpt_model(model_name: str = None) -> bool:
    """ä¸‹è½½OceanGPTæ¨¡å‹"""
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # ç¡®å®šè¦ä¸‹è½½çš„æ¨¡å‹
    if model_name is None:
        model_name = config.get('model_name', 'OceanGPT-o-7B-v0.1')
    
    if model_name not in config['oceangpt_models']:
        logger.error(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_name}")
        return False
    
    model_config = config['oceangpt_models'][model_name]
    local_path = config['model_local_paths'][model_name]
    
    logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½OceanGPTæ¨¡å‹: {model_name}")
    logger.info(f"ğŸ“ æ¨¡å‹æè¿°: {model_config['description']}")
    logger.info(f"ğŸ“‚ æœ¬åœ°è·¯å¾„: {local_path}")
    
    # æ£€æŸ¥ç°æœ‰æ–‡ä»¶
    if os.path.exists(local_path):
        logger.info("ğŸ“ å‘ç°ç°æœ‰æ¨¡å‹ç›®å½•ï¼Œæ£€æŸ¥å®Œæ•´æ€§...")
        if check_model_integrity(local_path):
            logger.info("âœ… æ¨¡å‹å·²å®Œæ•´ä¸‹è½½")
            return True
        else:
            logger.info("ğŸ”„ æ¨¡å‹ä¸å®Œæ•´ï¼Œç»§ç»­ä¸‹è½½...")
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs('logs', exist_ok=True)
    
    # å°è¯•ä¸‹è½½
    preferred_source = config['model_download']['preferred_source']
    fallback_source = config['model_download']['fallback_source']
    
    success = False
    
    if preferred_source == 'modelscope':
        logger.info("ğŸŒ ä½¿ç”¨ModelScopeä½œä¸ºé¦–é€‰ä¸‹è½½æº")
        success = download_from_modelscope(
            model_config['modelscope_id'], 
            local_path
        )
        
        if not success and fallback_source == 'huggingface':
            logger.info("ğŸ”„ ModelScopeå¤±è´¥ï¼Œå°è¯•HuggingFace...")
            success = download_from_huggingface(
                model_config['huggingface_id'], 
                local_path
            )
    
    elif preferred_source == 'huggingface':
        logger.info("ğŸŒ ä½¿ç”¨HuggingFaceä½œä¸ºé¦–é€‰ä¸‹è½½æº")
        success = download_from_huggingface(
            model_config['huggingface_id'], 
            local_path
        )
        
        if not success and fallback_source == 'modelscope':
            logger.info("ğŸ”„ HuggingFaceå¤±è´¥ï¼Œå°è¯•ModelScope...")
            success = download_from_modelscope(
                model_config['modelscope_id'], 
                local_path
            )
    
    if success:
        # éªŒè¯ä¸‹è½½å®Œæ•´æ€§
        if check_model_integrity(local_path):
            logger.info(f"ğŸ‰ {model_name} ä¸‹è½½å®Œæˆä¸”éªŒè¯é€šè¿‡!")
            return True
        else:
            logger.error(f"âŒ {model_name} ä¸‹è½½å®Œæˆä½†éªŒè¯å¤±è´¥")
            return False
    else:
        logger.error(f"âŒ {model_name} ä¸‹è½½å¤±è´¥")
        return False

def download_all_models():
    """ä¸‹è½½æ‰€æœ‰æ¨èçš„OceanGPTæ¨¡å‹"""
    config = load_config()
    
    for model_name, model_config in config['oceangpt_models'].items():
        if model_config.get('recommended', False):
            logger.info(f"\n{'='*50}")
            logger.info(f"ä¸‹è½½æ¨èæ¨¡å‹: {model_name}")
            logger.info(f"{'='*50}")
            
            success = download_oceangpt_model(model_name)
            if not success:
                logger.error(f"æ¨¡å‹ {model_name} ä¸‹è½½å¤±è´¥")
            
            time.sleep(2)  # çŸ­æš‚ä¼‘æ¯

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸‹è½½OceanGPTæ¨¡å‹')
    parser.add_argument('--model', '-m', type=str, help='æŒ‡å®šè¦ä¸‹è½½çš„æ¨¡å‹åç§°')
    parser.add_argument('--all', '-a', action='store_true', help='ä¸‹è½½æ‰€æœ‰æ¨èæ¨¡å‹')
    
    args = parser.parse_args()
    
    if args.all:
        download_all_models()
    elif args.model:
        download_oceangpt_model(args.model)
    else:
        # é»˜è®¤ä¸‹è½½é…ç½®ä¸­æŒ‡å®šçš„å½“å‰æ¨¡å‹
        download_oceangpt_model() 