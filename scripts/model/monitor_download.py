#!/usr/bin/env python3
"""
ç›‘æ§OceanGPTæ¨¡å‹ä¸‹è½½è¿›åº¦

 ä¸ `scripts/model/manage.py` è„šæœ¬é…åˆä½¿ç”¨ã€‚
"""

import os
import time
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[2]

def format_file_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f}{size_names[i]}"

def monitor_download_progress():
    """ç›‘æ§ä¸‹è½½è¿›åº¦"""
    model_path = REPO_ROOT / "models/OceanGPT-o-7B-v0.1/ZJUNLP/OceanGPT-o-7B"
    
    if not model_path.exists():
        print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        return
    
    print("ğŸ” ç›‘æ§OceanGPT-o-7Bæ¨¡å‹ä¸‹è½½è¿›åº¦...")
    print("=" * 60)
    
    while True:
        if not model_path.exists():
            print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
            break
            
        # ç»Ÿè®¡æ–‡ä»¶
        all_files = list(model_path.glob("*"))
        total_files = len(all_files)
        total_size = sum(f.stat().st_size for f in all_files if f.is_file())
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files = {
            "config.json": model_path / "config.json",
            "tokenizer.json": model_path / "tokenizer.json", 
            "tokenizer_config.json": model_path / "tokenizer_config.json",
        }
        
        # æŸ¥æ‰¾.safetensorsæ–‡ä»¶
        safetensors_files = list(model_path.glob("*.safetensors"))
        
        print(f"â° {time.strftime('%H:%M:%S')}")
        print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"ğŸ“Š æ€»å¤§å°: {format_file_size(total_size)}")
        
        print("\nğŸ”‘ å…³é”®æ–‡ä»¶çŠ¶æ€:")
        for name, file_path in key_files.items():
            status = "âœ…" if file_path.exists() else "âŒ"
            size = format_file_size(file_path.stat().st_size) if file_path.exists() else "0B"
            print(f"  {status} {name}: {size}")
        
        print(f"\nâš–ï¸  æ¨¡å‹æƒé‡æ–‡ä»¶ (.safetensors): {len(safetensors_files)} ä¸ª")
        for sf in safetensors_files:
            size = format_file_size(sf.stat().st_size)
            print(f"  âœ… {sf.name}: {size}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸‹è½½å®Œæˆ
        has_safetensors = len(safetensors_files) > 0
        has_key_files = all(kf.exists() for kf in key_files.values())
        
        if has_safetensors and has_key_files:
            print("\nğŸ‰ æ¨¡å‹ä¸‹è½½å¯èƒ½å·²å®Œæˆï¼")
            print("å»ºè®®è¿è¡ŒéªŒè¯è„šæœ¬ç¡®è®¤æ–‡ä»¶å®Œæ•´æ€§")
            break
        
        print("\nâ³ ä¸‹è½½ä¸­... (30ç§’ååˆ·æ–°)")
        print("=" * 60)
        
        try:
            time.sleep(30)
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸  ç›‘æ§å·²åœæ­¢")
            break

if __name__ == "__main__":
    monitor_download_progress() 